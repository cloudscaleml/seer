{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.53\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register/Reference a Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "#                                             datastore_name='seerdata', \n",
    "#                                             container_name='your azure blob container name',\n",
    "#                                             account_name='your storage account name', \n",
    "#                                             account_key='your storage account key',\n",
    "#                                             create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workspacefilestore': <azureml.data.azure_storage_datastore.AzureFileDatastore at 0x1a159de73c8>,\n",
       " 'workspaceblobstore': <azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x1a159dee278>,\n",
       " 'halworkspacestorage__datasets': <azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x1a159de7e10>,\n",
       " 'seerdata': <azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x1a159de7d30>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# workspace\n",
    "ws = Workspace.from_config()\n",
    "ws.datastores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "datastore = ws.datastores['seerdata']\n",
    "\n",
    "# compute target\n",
    "compute = ws.compute_targets['gandalf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pipeline!\n",
    "The following will be created and then run:\n",
    "1. Pipeline Parameters\n",
    "2. Data Fetch Step\n",
    "3. Data Process Step\n",
    "4. Training Step\n",
    "5. Model Registration Step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parameters\n",
    "We need to tell the Pipeline what it needs to learn to see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = DataPath(datastore=datastore, path_on_datastore='burrito_tacos')\n",
    "data_path_pipeline_param = (PipelineParameter(name=\"data\", \n",
    "                                             default_value=datapath), \n",
    "                                             DataPathComputeBinding(mode='mount'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seer_tfrecords = PipelineData(\n",
    "    \"tfrecords_set\",\n",
    "    datastore=datastore,\n",
    "    is_directory=True\n",
    ")\n",
    "\n",
    "prep = Estimator(source_directory='.',\n",
    "                      compute_target=compute,\n",
    "                      entry_script='parse.py',\n",
    "                      use_gpu=True,\n",
    "                      pip_requirements_file='requirements.txt')\n",
    "\n",
    "prepStep = EstimatorStep(\n",
    "    name='Data Preparation',\n",
    "    estimator=prep,\n",
    "    estimator_entry_script_arguments=[\"--source_path\", data_path_pipeline_param, \n",
    "                                      \"--target_path\", seer_tfrecords],\n",
    "    inputs=[data_path_pipeline_param],\n",
    "    outputs=[seer_tfrecords],\n",
    "    compute_target=compute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seer_training = PipelineData(\n",
    "    \"train\",\n",
    "    datastore=datastore,\n",
    "    is_directory=True\n",
    ")\n",
    "\n",
    "train = Estimator(source_directory='.',\n",
    "                      compute_target=compute,\n",
    "                      entry_script='train.py',\n",
    "                      use_gpu=True,\n",
    "                      pip_requirements_file='requirements.txt')\n",
    "\n",
    "trainStep = EstimatorStep(\n",
    "    name='Model Training',\n",
    "    estimator=train,\n",
    "    estimator_entry_script_arguments=[\"--source_path\", seer_tfrecords, \n",
    "                                      \"--target_path\", seer_training,\n",
    "                                      \"--epochs\", 5,\n",
    "                                      \"--batch\", 10,\n",
    "                                      \"--lr\", 0.001],\n",
    "    inputs=[seer_tfrecords],\n",
    "    outputs=[seer_training],\n",
    "    compute_target=compute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seer_model = PipelineData(\n",
    "    \"model\",\n",
    "    datastore=datastore,\n",
    "    is_directory=True\n",
    ")\n",
    "\n",
    "register = Estimator(source_directory='.',\n",
    "                      compute_target=compute,\n",
    "                      entry_script='register.py',\n",
    "                      use_gpu=True)\n",
    "\n",
    "registerStep = EstimatorStep(\n",
    "    name='Model Registration',\n",
    "    estimator=register,\n",
    "    estimator_entry_script_arguments=[\"--source_path\", seer_training, \n",
    "                                      \"--target_path\", seer_model],\n",
    "    inputs=[seer_training],\n",
    "    outputs=[seer_model],\n",
    "    compute_target=compute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline(workspace=ws, steps=[prepStep, trainStep, registerStep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Data Preparation [02604895][4b0bb612-e14f-48b9-9b19-128eccef855a], (This step will run and generate new outputs)\n",
      "Created step Model Training [45a9879e][684eba98-2534-4ae5-aaef-1970b280c524], (This step will run and generate new outputs)\n",
      "Created step Model Registration [8dc3f5d1][aa6b60cd-128d-4d27-9c5e-f3775ace5450], (This step will run and generate new outputs)\n",
      "Using data reference seerdata_9193bbcf for StepId [21012319][09ab9570-092e-42a4-beba-13183967e861], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: 05c520ed-bf59-4618-9d58-c9f2e9b71031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0797fc56d2524d1dbf23a62eaad5642e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfaa46d2748f472cb3abc4d6c3efa9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Submit the pipeline to be run\n",
    "pipeline_run1 = Experiment(ws, 'seer').submit(pipeline1)\n",
    "RunDetails(pipeline_run1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_run1.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline1 = pipeline1.publish(\n",
    "    name=\"Seer Pipeline\", \n",
    "    description=\"Transfer learned image classifier. Uses folders as labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
